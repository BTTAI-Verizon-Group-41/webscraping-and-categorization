{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "772605c7-5c0e-4dc0-8ee9-72eaaa6cc9bc",
   "metadata": {},
   "source": [
    "# Prepare the complete data set\n",
    "\n",
    "This notebook integrates the contents of the urls from \"keywords_emptyText.csv\" into the data set with all urls\n",
    "\n",
    "Verizon, Group 41\n",
    "<br>Athena Bai, Tia Zheng, Kathy Yang, Tapuwa Kabaira, Chris Smith\n",
    "\n",
    "Last updated: Nov. 28, 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ab13810-3480-4b11-adc5-20ccca76e85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcd766bd-0be9-4d78-a1e0-c69961e5d1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data files\n",
    "working_urls = pd.read_csv(\"df_text.csv\", header=0)\n",
    "remaining_urls = pd.read_csv(\"remaining_contents.csv\", header=0)\n",
    "labels = pd.read_csv(\"categorizedurls.csv\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17b8a44f-076d-4722-9db7-df22d7ea5865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['url', ' category', 'text_content', 'Text_Length', 'text_cleaned',\n",
       "       'Sentiment'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_urls.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1adb8e4-7785-4078-848c-7f3509ebe46f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['url', 'content'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remaining_urls.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a457e6c0-c7b7-45d2-ac25-041068fe57a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of each DataFrame\n",
    "working_urls = working_urls.copy()\n",
    "remaining_urls = remaining_urls.copy()\n",
    "labels = labels.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de50d18e-a100-4b39-98f5-82c71ade6385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "to_translate = '你好，世界！'\n",
    "translated = GoogleTranslator(source='zh-CN', target='en').translate(to_translate)\n",
    "print(translated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e425f1-4510-4d21-bf68-f5461f6ee9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add features to the remaining urls\n",
    "remaining_urls['content'] = remaining_urls['text_content'].str.len().fillna(0)\n",
    "df['text_cleaned'] = df['text_content'].apply(preprocess_text)\n",
    "df['Sentiment'] = df['text_cleaned'].apply(calc_sentiment)\n",
    "df['lexical_diversity'] = df['text_content'].apply(lexical_diversity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ab0b5c-a9d2-41b0-9ea6-542c47e10f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare df2 to match df1's structure with None for missing columns\n",
    "df2_prepared = df2[['url']].copy()\n",
    "df2_prepared['category'] = None\n",
    "df2_prepared['text_content'] = None\n",
    "df2_prepared['Text_Length'] = None\n",
    "df2_prepared['text_cleaned'] = None\n",
    "df2_prepared['Sentiment'] = None\n",
    "\n",
    "# Concatenate df1 and prepared df2\n",
    "df_combined = pd.concat([df1, df2_prepared], ignore_index=True)\n",
    "\n",
    "# Merge with df3 to ensure the correct order based on 'url' and fill the 'category' column\n",
    "df4 = df3[['url', 'category']].merge(\n",
    "    df_combined, on=['url', 'category'], how='left'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
