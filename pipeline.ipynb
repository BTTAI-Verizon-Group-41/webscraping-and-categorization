{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16c106de-0c68-4c44-9091-940d15c60f0b",
   "metadata": {},
   "source": [
    "# Automated Website categorization using machine learning algorithms\n",
    "\n",
    "This notebook processes the website data and builds an ML model to predict the category of the website.\n",
    "\n",
    "Verizon, Group 41\n",
    "Athena Bai, Tia Zheng, Kathy Yang, Tapuwa Kabaira, Chris Smith\n",
    "\n",
    "Nov. 1, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5121e610-15cb-4397-b35b-785eb4c92d41",
   "metadata": {},
   "source": [
    "## 1. Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b53d385b-71f2-4d95-8b40-9ccf2f850fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "#from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5287534c-3e71-4413-9cb8-5bf4373a4d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read labels\n",
    "cat_urls = pd.read_csv(\"categorizedurls.csv\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c36f180a-27d4-43d8-a011-4b13d1972794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read features\n",
    "url_ending_df = pd.read_csv(\"output_with_url_endings.csv\", header=0)\n",
    "sentiment_df = pd.read_csv(\"output_with_sentiment.csv\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e273bcc4-9a1f-4e5a-b59f-6719544ed0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the urls, features and labels into one csv\n",
    "tmp1 = cat_urls.iloc[:, 0]\n",
    "tmp2 = sentiment_df.iloc[:, [2, 3]] # Columns: Sentiment Score and Sentiment Magnitude \n",
    "tmp3 = url_ending_df.iloc[:, 0]\n",
    "tmp4 = cat_urls.iloc[:, 1]\n",
    "\n",
    "df = pd.concat([tmp1, tmp2, tmp3, tmp4], axis=1)\n",
    "\n",
    "# Save the combined data\n",
    "df.to_csv('data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d75da0-9710-4e10-b8af-7ee0d9bec269",
   "metadata": {},
   "source": [
    "## 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22b5b9d9-1470-4946-b3cf-0a8eb3f7d23b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['url', 'Sentiment Score', 'Sentiment Magnitude', 'url_ending',\n",
       "       'category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36639cd3-0835-4661-a916-f48892c82238",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(df.columns)\n",
    "features.remove('url')\n",
    "features.remove('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70eb8fea-2198-4576-86c7-740e67204b09",
   "metadata": {},
   "source": [
    "### Missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c096259a-12a7-4f26-94ae-b7e2aef4e23f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "url                      0\n",
       "Sentiment Score        993\n",
       "Sentiment Magnitude    993\n",
       "url_ending               0\n",
       "category                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check null data\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11d146c7-943a-4652-ad19-2773b8ac6d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possible: mean/median imputation, mode imputation, KNN imputation, regression imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a0e54e3-eefe-4662-9d52-336d4dfe2568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of mean imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1ed2def-399e-4c9e-a147-812dfdacb47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "numeric_df_imputed = numeric_df.fillna(numeric_df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ba0aefc-7aa9-4d6a-adf4-6dff535711d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following line to inspect the processed data\n",
    "# numeric_df_imputed.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76be2273-b126-4dcb-bc3f-fbe3dc84f707",
   "metadata": {},
   "source": [
    "Comment:\n",
    "This might not yield good predictions as the missing data are too much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4da9305-9990-437d-9129-4aa3c57c68d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### One-hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99d21d6c-e12d-4f5b-8bdf-a0834f3f51ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all columns of type object\n",
    "to_encode = list(df.select_dtypes(include=['object']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa7d1b9b-f463-4191-a487-9c962875c77a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "url           1000\n",
       "url_ending      18\n",
       "category        50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the number of unique values each column has: (from lab3)\n",
    "df[to_encode].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "64405320-3e44-4276-bf71-5d590d534b66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['com', 'org', 'gov', 'net', 'fm', 'tv', 'us', 'edu', 'co', 'ly']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only encode some of the most frequent url endings.\n",
    "# Otherwise one-hot encoding will slow down the computation.\n",
    "top_10_ending = list(df['url_ending'].value_counts().head(10).index)\n",
    "top_10_ending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "446cfa2a-87c0-4376-830b-5598504dcd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "for value in top_10_ending:\n",
    "    df['url_ending'+ value] = np.where(df['url_ending']==value,1,0)\n",
    "    \n",
    "# Remove the original column from the df\n",
    "df.drop(columns = 'url_ending', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3e0801-29ad-45a2-80b4-ef20cae3d52f",
   "metadata": {},
   "source": [
    "## 3. Preparation for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d546b4a3-aa88-4fb3-966f-c1208b927900",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['category', 'url'])\n",
    "y = df['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a1f6f468-a122-4d6f-833a-4df922dcb587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc50b245-4385-452d-94a9-d88ad8257b76",
   "metadata": {},
   "source": [
    "## 4. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0513ac8a-c7be-40e9-8952-c9dd6cbe1666",
   "metadata": {},
   "source": [
    "### Train two Decision Tree Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6a31151e-33af-4f04-8eb2-dfddfe1458f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have assigned a default value of 'entropy' to the crit parameter.\n",
    "# scikit-learn's default value for min_samples_leaf is 1.\n",
    "def train_test_DT(X_train, X_test, y_train, y_test, depth, crit='entropy'):\n",
    "    \n",
    "    # Train a Decision Tree classifier on the training data\n",
    "    model = DecisionTreeClassifier(max_depth = depth, criterion = crit)\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    class_label_predictions = model.predict(X_test)\n",
    "    \n",
    "    # Compute the accuracy\n",
    "    acc_score = accuracy_score(y_test, class_label_predictions)\n",
    "    \n",
    "    return acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7c49d4d8-9fc2-46bb-ad3d-f38f6447cf98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth=8, accuracy score: 0.24\n",
      "Max Depth=64, accuracy score: 0.24\n"
     ]
    }
   ],
   "source": [
    "depth1= 8\n",
    "depth2 = 64\n",
    "\n",
    "max_depth_range = [depth1, depth2]\n",
    "acc = []\n",
    "\n",
    "for md in max_depth_range:\n",
    "    score = train_test_DT(X_train, X_test, y_train, y_test, md)\n",
    "    acc.append(float(score))\n",
    "    print('Max Depth=' + str(md) + ', accuracy score: ' + str(score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
