{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f13e601b",
   "metadata": {},
   "source": [
    "# Automated Website categorization using machine learning algorithms (DT)\n",
    "\n",
    "This notebook processes the website contents data and builds a BERT model to predict the category of websites.\n",
    "\n",
    "BERT (Bidirectional Encoder Representations from Transformers) is an advanced NLP model that provides deep contextual understanding of language. Unlike traditional models, BERT can interpret the meaning of words in context, significantly improving the accuracy of text classification tasks.\n",
    "\n",
    "## Stages of the project\n",
    "- Web Scraping: Extract textual content from websites using tools like BeautifulSoup and Selenium.\n",
    "- Data Preprocessing: Prepare and clean the text data for input into the model.\n",
    "- Modeling: Decision Tree, Regression Tree, BERT\n",
    "- Output Results: Evaluate the model performance.\n",
    "\n",
    "## Model implementation in this file\n",
    "The BERT model is implemented using the Hugging Face Transformers library. The following steps are performed:\n",
    "1. Prepare Data\n",
    "2. Preprocessing\n",
    "3. Modeling & Fine-tuning\n",
    "4. Evaluation using different metrics (e.g. accuracy, precision, recall)\n",
    "\n",
    "Verizon, Group 41\n",
    "<br>Athena Bai, Tia Zheng, Kathy Yang, Tapuwa Kabaira, Chris Smith\n",
    "\n",
    "Last updated: Dec. 1, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30528de1-21a8-4488-9905-24567359e6f1",
   "metadata": {},
   "source": [
    "## 0. Package preparation (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dba941b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in d:\\miniconda3\\envs\\cosi114a\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\shapinb\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in d:\\miniconda3\\envs\\cosi114a\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\miniconda3\\envs\\cosi114a\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\miniconda3\\envs\\cosi114a\\lib\\site-packages (from scikit-learn) (3.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~umpy (D:\\miniconda3\\envs\\cosi114a\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (D:\\miniconda3\\envs\\cosi114a\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (D:\\miniconda3\\envs\\cosi114a\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "# Install Scikit-learn for evaluation metrics\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26b14d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in d:\\miniconda3\\envs\\cosi114a\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in d:\\miniconda3\\envs\\cosi114a\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in d:\\miniconda3\\envs\\cosi114a\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: setuptools in d:\\miniconda3\\envs\\cosi114a\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\miniconda3\\envs\\cosi114a\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: networkx in d:\\miniconda3\\envs\\cosi114a\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in d:\\miniconda3\\envs\\cosi114a\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in d:\\miniconda3\\envs\\cosi114a\\lib\\site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\miniconda3\\envs\\cosi114a\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\miniconda3\\envs\\cosi114a\\lib\\site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~umpy (D:\\miniconda3\\envs\\cosi114a\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (D:\\miniconda3\\envs\\cosi114a\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (D:\\miniconda3\\envs\\cosi114a\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2ce1eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in d:\\miniconda3\\envs\\cosi114a\\lib\\site-packages (4.46.2)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~umpy (D:\\miniconda3\\envs\\cosi114a\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (D:\\miniconda3\\envs\\cosi114a\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (D:\\miniconda3\\envs\\cosi114a\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: filelock in d:\\miniconda3\\envs\\cosi114a\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in d:\\miniconda3\\envs\\cosi114a\\lib\\site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\shapinb\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\miniconda3\\envs\\cosi114a\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\miniconda3\\envs\\cosi114a\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\miniconda3\\envs\\cosi114a\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in d:\\miniconda3\\envs\\cosi114a\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in d:\\miniconda3\\envs\\cosi114a\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in d:\\miniconda3\\envs\\cosi114a\\lib\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\miniconda3\\envs\\cosi114a\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\miniconda3\\envs\\cosi114a\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\miniconda3\\envs\\cosi114a\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in d:\\miniconda3\\envs\\cosi114a\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\miniconda3\\envs\\cosi114a\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\miniconda3\\envs\\cosi114a\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\miniconda3\\envs\\cosi114a\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\miniconda3\\envs\\cosi114a\\lib\\site-packages (from requests->transformers) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e227946b-99b5-4244-9c2d-e15b92f32a45",
   "metadata": {},
   "source": [
    "## 1. Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ba0f16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda3\\envs\\cosi114a\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Modeling\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import AdamW\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16ac58be-84b5-43b4-be49-8a69c0d6183e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set environemntal varibales so that the chache uses d disk space instead c disk space\n",
    "# import os\n",
    "# os.environ[\"TRANSFORMERS_CACHE\"] = \"D:/huggingface_cache\"\n",
    "\n",
    "# import os\n",
    "# os.environ[\"TORCH_HOME\"] = \"D:/torch_cache\"\n",
    "\n",
    "import os\n",
    "\n",
    "# Set Hugging Face cache directory\n",
    "os.environ['HF_HOME'] = 'D:\\\\huggingface_cache'  # Or your preferred folder\n",
    "\n",
    "import tempfile\n",
    "\n",
    "# Set temporary directory\n",
    "tempfile.tempdir = 'D:\\\\temp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dab32a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_from_check.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f6b68a5-1ef5-4d74-ba1c-9499a8ce025a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['url',\n",
       " 'category',\n",
       " 'text_content',\n",
       " 'Text_Length',\n",
       " 'text_cleaned',\n",
       " 'Sentiment',\n",
       " 'lexical_diversity']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08ef7809-e3c7-42a3-89ab-89dd62f02f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the target labels\n",
    "label_encoder = LabelEncoder()\n",
    "data['category'] = label_encoder.fit_transform(data['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8402fdf5-c8d1-469f-8999-68562d047d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text_content'] = data['text_content'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "453b0a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset Class for BERT\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {key: val.squeeze(0) for key, val in encoding.items()}, torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f68821e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer and Dataset Preparation\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "dataset = TextDataset(data['text_content'].tolist(), data['category'].tolist(), tokenizer)\n",
    "\n",
    "# Train-Test Split\n",
    "train_size = int(0.8 * len(dataset))\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, len(dataset) - train_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37e08bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "D:\\miniconda3\\envs\\cosi114a\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch 0: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 37/37 [37:55<00:00, 61.50s/it, loss=3.54]\n",
      "Epoch 1: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 37/37 [50:13<00:00, 81.45s/it, loss=3.01]\n",
      "Epoch 2: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 37/37 [54:20<00:00, 88.12s/it, loss=2.78]\n"
     ]
    }
   ],
   "source": [
    "# Load BERT and Train\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_encoder.classes_))\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Training Loop\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "    for batch in loop:\n",
    "        inputs, labels = batch\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(**inputs, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7b79d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        inputs, labels = batch\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "422770ed-2643-482d-8cb9-281a6e8a53a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classes in all_labels: {0, 1, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 31, 32, 33, 34, 36, 39, 40, 41}\n",
      "Unique classes in all_preds: {32, 22}\n",
      "Classes in label_encoder: ['Business and Economy' 'Computer and Internet Info'\n",
      " 'Content Delivery Networks' 'Dating' 'Educational Institutions'\n",
      " 'Entertainment and Arts' 'Financial Services' 'Food & Drink'\n",
      " 'Food and Beverage' 'Food and Dining' 'Food and Drink' 'Gambling' 'Games'\n",
      " 'Government' 'Health and Medicine' 'Home and Garden'\n",
      " 'Internet Communications and Telephony' 'Internet Portals' 'Job Search'\n",
      " 'Military' 'Motor Vehicles' 'Music' 'News' 'Online Storage and Backup'\n",
      " 'Personal Sites and Blogs' 'Real Estate' 'Recreation and Hobbies'\n",
      " 'Reference and Research' 'Religion' 'Science' 'Science and Technology'\n",
      " 'Search Engines' 'Shopping' 'Smart Home' 'Social Networking' 'Society'\n",
      " 'Sports' 'Sports and Fitness' 'Stock Advice and Tools' 'Streaming Media'\n",
      " 'Technology' 'Travel' 'Weather' 'Web Advertisements' 'Web Hosting']\n",
      "Number of classes in label_encoder: 45\n",
      "                                       precision    recall  f1-score   support\n",
      "\n",
      "                 Business and Economy       0.00      0.00      0.00        10\n",
      "           Computer and Internet Info       0.00      0.00      0.00         6\n",
      "                               Dating       0.00      0.00      0.00         1\n",
      "             Educational Institutions       0.00      0.00      0.00         2\n",
      "               Entertainment and Arts       0.00      0.00      0.00        10\n",
      "                   Financial Services       0.00      0.00      0.00         7\n",
      "                    Food and Beverage       0.00      0.00      0.00         3\n",
      "                      Food and Dining       0.00      0.00      0.00         1\n",
      "                       Food and Drink       0.00      0.00      0.00         2\n",
      "                             Gambling       0.00      0.00      0.00         3\n",
      "                                Games       0.00      0.00      0.00         3\n",
      "                           Government       0.00      0.00      0.00         4\n",
      "                  Health and Medicine       0.00      0.00      0.00         5\n",
      "                      Home and Garden       0.00      0.00      0.00         1\n",
      "Internet Communications and Telephony       0.00      0.00      0.00         6\n",
      "                     Internet Portals       0.00      0.00      0.00         1\n",
      "                           Job Search       0.00      0.00      0.00         1\n",
      "                             Military       0.00      0.00      0.00         1\n",
      "                       Motor Vehicles       0.00      0.00      0.00         3\n",
      "                                Music       0.00      0.00      0.00         1\n",
      "                                 News       0.39      1.00      0.56        14\n",
      "            Online Storage and Backup       0.00      0.00      0.00         1\n",
      "             Personal Sites and Blogs       0.00      0.00      0.00         1\n",
      "                          Real Estate       0.00      0.00      0.00         5\n",
      "               Recreation and Hobbies       0.00      0.00      0.00         1\n",
      "               Reference and Research       0.00      0.00      0.00         2\n",
      "                       Search Engines       0.00      0.00      0.00         1\n",
      "                             Shopping       0.32      0.97      0.48        36\n",
      "                           Smart Home       0.00      0.00      0.00         1\n",
      "                    Social Networking       0.00      0.00      0.00         3\n",
      "                               Sports       0.00      0.00      0.00         3\n",
      "                      Streaming Media       0.00      0.00      0.00         2\n",
      "                           Technology       0.00      0.00      0.00         1\n",
      "                               Travel       0.00      0.00      0.00         5\n",
      "\n",
      "                             accuracy                           0.33       147\n",
      "                            macro avg       0.02      0.06      0.03       147\n",
      "                         weighted avg       0.11      0.33      0.17       147\n",
      "\n",
      "Accuracy: 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda3\\envs\\cosi114a\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\miniconda3\\envs\\cosi114a\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\miniconda3\\envs\\cosi114a\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Solve error: Number of classes, 34,does not match size\n",
    "# of target_names, 45. Try specifying the labels parameter\n",
    "print(\"Unique classes in all_labels:\", set(all_labels))\n",
    "print(\"Unique classes in all_preds:\", set(all_preds))\n",
    "print(\"Classes in label_encoder:\", label_encoder.classes_)\n",
    "print(\"Number of classes in label_encoder:\", len(label_encoder.classes_))\n",
    "\n",
    "# Generate Classification Report\n",
    "unique_labels = sorted(set(all_labels))\n",
    "print(classification_report(all_labels, all_preds, labels=unique_labels, target_names=[label_encoder.classes_[i] for i in unique_labels]))\n",
    "# print(classification_report(all_labels, all_preds, target_names=label_encoder.classes_))\n",
    "print(\"Accuracy:\", accuracy_score(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9943c8b2-c942-4183-a176-f54dcc83f7bf",
   "metadata": {},
   "source": [
    "## Results with epochs = 3\n",
    "Epoch 0: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 37/37 \\[37:55<00:00, 61.50s/it, loss=3.54\\]\n",
    "\n",
    "Epoch 1: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 37/37 \\[50:13<00:00, 81.45s/it, loss=3.01\\]\n",
    "\n",
    "Epoch 2: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 37/37 \\[54:20<00:00, 88.12s/it, loss=2.78\\]\n",
    "\n",
    "Unique classes in all_labels: {0, 1, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 31, 32, 33, 34, 36, 39, 40, 41}\n",
    "\n",
    "Unique classes in all_preds: {32, 22}\n",
    "\n",
    "Classes in label_encoder: \\['Business and Economy' 'Computer and Internet Info'\n",
    " 'Content Delivery Networks' 'Dating' 'Educational Institutions'\n",
    " 'Entertainment and Arts' 'Financial Services' 'Food & Drink'\n",
    " 'Food and Beverage' 'Food and Dining' 'Food and Drink' 'Gambling' 'Games'\n",
    " 'Government' 'Health and Medicine' 'Home and Garden'\n",
    " 'Internet Communications and Telephony' 'Internet Portals' 'Job Search'\n",
    " 'Military' 'Motor Vehicles' 'Music' 'News' 'Online Storage and Backup'\n",
    " 'Personal Sites and Blogs' 'Real Estate' 'Recreation and Hobbies'\n",
    " 'Reference and Research' 'Religion' 'Science' 'Science and Technology'\n",
    " 'Search Engines' 'Shopping' 'Smart Home' 'Social Networking' 'Society'\n",
    " 'Sports' 'Sports and Fitness' 'Stock Advice and Tools' 'Streaming Media'\n",
    " 'Technology' 'Travel' 'Weather' 'Web Advertisements' 'Web Hosting'\\]\n",
    "Number of classes in label_encoder: 45\n",
    "                                       precision    recall  f1-score   support\n",
    "\n",
    "                 Business and Economy       0.00      0.00      0.00        10\n",
    "           Computer and Internet Info       0.00      0.00      0.00         6\n",
    "                               Dating       0.00      0.00      0.00         1\n",
    "             Educational Institutions       0.00      0.00      0.00         2\n",
    "               Entertainment and Arts       0.00      0.00      0.00        10\n",
    "                   Financial Services       0.00      0.00      0.00         7\n",
    "                    Food and Beverage       0.00      0.00      0.00         3\n",
    "                      Food and Dining       0.00      0.00      0.00         1\n",
    "                       Food and Drink       0.00      0.00      0.00         2\n",
    "                             Gambling       0.00      0.00      0.00         3\n",
    "                                Games       0.00      0.00      0.00         3\n",
    "                           Government       0.00      0.00      0.00         4\n",
    "                  Health and Medicine       0.00      0.00      0.00         5\n",
    "                      Home and Garden       0.00      0.00      0.00         1\n",
    "    Internet Communications and Telephony       0.00      0.00      0.00         6\n",
    "                     Internet Portals       0.00      0.00      0.00         1\n",
    "                           Job Search       0.00      0.00      0.00         1\n",
    "                             Military       0.00      0.00      0.00         1\n",
    "                       Motor Vehicles       0.00      0.00      0.00         3\n",
    "                                Music       0.00      0.00      0.00         1\n",
    "                                 News       0.39      1.00      0.56        14\n",
    "            Online Storage and Backup       0.00      0.00      0.00         1\n",
    "             Personal Sites and Blogs       0.00      0.00      0.00         1\n",
    "                          Real Estate       0.00      0.00      0.00         5\n",
    "               Recreation and Hobbies       0.00      0.00      0.00         1\n",
    "               Reference and Research       0.00      0.00      0.00         2\n",
    "                       Search Engines       0.00      0.00      0.00         1\n",
    "                             Shopping       0.32      0.97      0.48        36\n",
    "                           Smart Home       0.00      0.00      0.00         1\n",
    "                    Social Networking       0.00      0.00      0.00         3\n",
    "                               Sports       0.00      0.00      0.00         3\n",
    "                      Streaming Media       0.00      0.00      0.00         2\n",
    "                           Technology       0.00      0.00      0.00         1\n",
    "                               Travel       0.00      0.00      0.00         5\n",
    "\n",
    "                             accuracy                           0.33       147\n",
    "                            macro avg       0.02      0.06      0.03       147\n",
    "                         weighted avg       0.11      0.33      0.17       147\n",
    "\n",
    "Accuracy: 0.3333333333333333"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
